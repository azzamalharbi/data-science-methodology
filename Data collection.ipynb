{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "## Data Collection",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Data Collection\n\n#### To solve the problem of detecting fraudulent credit card transactions, we need to collect data that contains both legitimate and fraudulent transactions. This dataset can be obtained from a financial institution or a publicly available dataset such as the **Kaggle Credit Card Fraud Detection Dataset**.\n\n### Key Data Points to Collect:\n\n1. **Transaction Details:**\n   - Transaction ID: A unique identifier for each transaction.\n   - Cardholder ID: A unique identifier for the cardholder, anonymized for privacy.\n   - Amount: The monetary value of the transaction.\n   - Merchant Category: The category of the merchant where the transaction occurred (e.g., retail, electronics, groceries).\n   - Location: The geographic location of the transaction.\n   - Transaction Time: The timestamp when the transaction took place.\n   - Mode of Transaction: Whether the transaction was online, in-store, or over the phone.\n\n2. **Cardholder Information:**\n   - Cardholder's spending history: Past spending behavior of the cardholder, including average transaction amount and frequency of transactions.\n   - Credit limit: The cardholderâ€™s maximum allowable credit.\n\n3. **Fraud Label:**\n   - A binary label indicating whether the transaction was fraudulent (1) or not (0).\n\n### Data Source:\n- **Kaggle Credit Card Fraud Detection Dataset:** This dataset contains 284,807 transactions made by European cardholders over two days in September 2013. The dataset is highly imbalanced, with only 492 frauds (0.172% of all transactions).\n\n- **Internal Bank Data:** If working with a bank or financial institution, we can use historical transaction data collected over a period of time, where fraudulent transactions are already identified and labeled.\n\n### Example Data Table:\n\n| Transaction ID | Cardholder ID | Amount | Merchant Category | Location | Transaction Time      | Mode of Transaction | Fraudulent |\n|----------------|---------------|--------|-------------------|----------|-----------------------|---------------------|------------|\n| 001            | 123           | 100    | Retail            | New York | 2024-01-01 10:00:00   | In-store            | No         |\n| 002            | 456           | 5000   | Electronics       | Online   | 2024-01-01 11:30:00   | Online              | Yes        |\n| 003            | 789           | 200    | Restaurant        | Chicago  | 2024-01-01 12:45:00   | In-store            | No         |\n| ...            | ...           | ...    | ...               | ...      | ...                   | ...                 | ...        |\n\nOnce the data is collected, we can proceed to the next step of **Data Understanding**, where we will analyze the structure and distributions within the dataset.\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Data Understanding\n\n#### The goal here is to identify patterns that differentiate fraudulent from legitimate transactions. \n\n**For example:**\n\n- Are there certain merchant categories that have more fraudulent transactions?\n- Is the transaction amount a significant factor?\n- Are there certain locations or times where fraud is more likely to occur?",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Data Preparation:\n\n#### The data will likely need cleaning and pre-processing before being used for modeling. Some steps include:\n\n- Handling missing values (e.g., missing transaction details).\n- Encoding categorical variables (e.g., mode of transaction).\n- Scaling numerical values (e.g., transaction amounts) to ensure consistency.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Modeling & Evaluations\n#### Using a labeled dataset, I can apply machine learning models such as:\n\n- Logistic Regression: To classify transactions as fraudulent or non-fraudulent.\n- Decision Trees/Random Forests: To capture non-linear patterns in the data.\n- Neural Networks: To identify complex relationships and patterns that might not be evident using traditional models.\n\n#### The performance of the model will be evaluated based on key metrics:\n\n- Accuracy: Overall percentage of correctly classified transactions.\n- Precision and Recall: Precision to ensure minimizing false positives (legitimate transactions marked as fraud) and recall to ensure catching as many fraudulent transactions as possible.\n- F1 Score: A balance between precision and recall.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}